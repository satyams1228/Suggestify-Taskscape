{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# Load CSV file\n",
    "file_path = 'Book1.csv'  # Replace with your actual file path\n",
    "#df = pd.read_csv(file_path, encoding='utf-8')\n",
    "df = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "#df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure the \"Task\" column is not empty\n",
    "df = df.dropna(subset=['Task'])\n",
    "\n",
    "# Load pre-trained DistilBERT model and tokenizer (a smaller version of BERT)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Batch processing for BERT embeddings\n",
    "batch_tasks = df['Task'].tolist()\n",
    "batch_tokens = tokenizer(batch_tasks, return_tensors='pt', truncation=True, padding=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    batch_outputs = model(**batch_tokens)\n",
    "\n",
    "# Extract embeddings for each task in the batch\n",
    "batch_embeddings = batch_outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "# Compute the cosine similarity between BERT embeddings\n",
    "cosine_sim = cosine_similarity(batch_embeddings, batch_embeddings)\n",
    "\n",
    "# Function to preprocess tasks\n",
    "def preprocess_task(task):\n",
    "    return task.lower().strip()\n",
    "\n",
    "# Function to get BERT embedding for a single task\n",
    "def get_embedding(task):\n",
    "    task_tokens = tokenizer(task, return_tensors='pt', truncation=True, padding=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        task_output = model(**task_tokens)\n",
    "\n",
    "    task_embedding = task_output.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    return task_embedding\n",
    "\n",
    "# Function to get recommendations based on BERT embedding similarity\n",
    "def get_recommendations(user_task, cosine_sim=cosine_sim, df=df):\n",
    "    user_task = preprocess_task(user_task)\n",
    "\n",
    "    # Use a more flexible string matching approach\n",
    "    task_matches = get_close_matches(user_task, df['Task'].apply(preprocess_task), n=2, cutoff=0.8)\n",
    "\n",
    "    if task_matches:\n",
    "        # Remove the exact match from the matches\n",
    "        task_matches = [match for match in task_matches if match != user_task]\n",
    "\n",
    "        if task_matches:\n",
    "            matched_task = task_matches[0]\n",
    "            task_indices = df[df['Task'].apply(preprocess_task) == matched_task].index\n",
    "            task_index = task_indices[0]\n",
    "\n",
    "            sim_scores = list(enumerate(cosine_sim[task_index]))\n",
    "            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "            sim_scores = sim_scores[:10]  # Get top 10 similar tasks\n",
    "\n",
    "            task_indices = [i[0] for i in sim_scores]\n",
    "            return df['Task'].iloc[task_indices]\n",
    "    \n",
    "    # If no close match is found, check for similarity within the dataset\n",
    "    user_embedding = get_embedding(user_task)\n",
    "    dataset_embeddings = batch_embeddings\n",
    "\n",
    "    # Compute cosine similarity between user's task and all tasks in the dataset\n",
    "    sim_scores = cosine_similarity([user_embedding], dataset_embeddings).flatten()\n",
    "    sim_scores = list(enumerate(sim_scores))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[:10]  # Get top 10 similar tasks in the dataset\n",
    "\n",
    "    task_indices = [i[0] for i in sim_scores]\n",
    "    return df['Task'].iloc[task_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended tasks for 'going for market':\n",
      "1387            Buy fresh produce from a farmer's market.\n",
      "126     Start a Collection of Something (e.g., stamps,...\n",
      "1305            Visit a local market for office supplies.\n",
      "4                          Write a To-Do List for the Day\n",
      "807        Visit a Local Farmer's Market or Street Market\n",
      "714                 Arrange a DIY T-Shirt Tie-Dye Station\n",
      "1837    Plan a weekend visit to an organic farmers' ma...\n",
      "53                                Visit a Farmer's Market\n",
      "475       Explore DIY Indian Pudding Making (e.g., Kheer)\n",
      "44                               Start a DIY Home Project\n",
      "Name: Task, dtype: object\n"
     ]
    }
   ],
   "source": [
    "user_task = 'going for market'\n",
    "recommendations = get_recommendations(user_task)\n",
    "print(f\"Recommended tasks for '{user_task}':\")\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
